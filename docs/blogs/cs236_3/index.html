<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://lazyCodes7.github.io/images/favicon.png" />
<title>CS236 Deep Generative Models (Part3) | Rishab Mudliar</title>
<meta name="title" content="CS236 Deep Generative Models (Part3)" />
<meta name="description" content="About These blogs are my notes that represent my interpretation of the CS236 course taught by Stefano.
Recap: Learning a generative model Recall that we want to learn a probability distribution p(x) over images x such that sampling from this distribution gives us new images. In the last part we dived deeper into probability distributions. Finally we saw ways to learn a probability distrubution for a discriminative model using techniques like logistic regression or neural models." />
<meta name="keywords" content="" />


<meta property="og:title" content="CS236 Deep Generative Models (Part3)" />
<meta property="og:description" content="About These blogs are my notes that represent my interpretation of the CS236 course taught by Stefano.
Recap: Learning a generative model Recall that we want to learn a probability distribution p(x) over images x such that sampling from this distribution gives us new images. In the last part we dived deeper into probability distributions. Finally we saw ways to learn a probability distrubution for a discriminative model using techniques like logistic regression or neural models." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lazyCodes7.github.io/blogs/cs236_3/" /><meta property="og:image" content="https://lazyCodes7.github.io/images/share.png"/><meta property="article:section" content="blogs" />
<meta property="article:published_time" content="2024-01-26T15:27:56+05:30" />
<meta property="article:modified_time" content="2024-01-26T15:27:56+05:30" /><meta property="og:site_name" content="Rishab M" />




<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://lazyCodes7.github.io/images/share.png"/>

<meta name="twitter:title" content="CS236 Deep Generative Models (Part3)"/>
<meta name="twitter:description" content="About These blogs are my notes that represent my interpretation of the CS236 course taught by Stefano.
Recap: Learning a generative model Recall that we want to learn a probability distribution p(x) over images x such that sampling from this distribution gives us new images. In the last part we dived deeper into probability distributions. Finally we saw ways to learn a probability distrubution for a discriminative model using techniques like logistic regression or neural models."/>



<meta itemprop="name" content="CS236 Deep Generative Models (Part3)">
<meta itemprop="description" content="About These blogs are my notes that represent my interpretation of the CS236 course taught by Stefano.
Recap: Learning a generative model Recall that we want to learn a probability distribution p(x) over images x such that sampling from this distribution gives us new images. In the last part we dived deeper into probability distributions. Finally we saw ways to learn a probability distrubution for a discriminative model using techniques like logistic regression or neural models."><meta itemprop="datePublished" content="2024-01-26T15:27:56+05:30" />
<meta itemprop="dateModified" content="2024-01-26T15:27:56+05:30" />
<meta itemprop="wordCount" content="1438"><meta itemprop="image" content="https://lazyCodes7.github.io/images/share.png"/>
<meta itemprop="keywords" content="" />
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  :root {
    --width: 720px;
    --font-main: Verdana, sans-serif;
    --font-secondary: Verdana, sans-serif;
    --font-scale: 1em;
    --background-color: #fff;
    --heading-color: #222;
    --text-color: #444;
    --link-color: #3273dc;
    --visited-color: #8b6fcb;
    --blockquote-color: #222;
  }

  @media (prefers-color-scheme: dark) {
    :root {
      --background-color: #01242e;
      --heading-color: #eee;
      --text-color: #ddd;
      --link-color: #8cc2dd;
      --visited-color: #8b6fcb;
      --blockquote-color: #ccc;
    }
  }

  body {
    font-family: var(--font-secondary);
    font-size: var(--font-scale);
    margin: auto;
    padding: 20px;
    max-width: var(--width);
    text-align: left;
    background-color: var(--background-color);
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: var(--text-color);
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    font-family: var(--font-main);
    color: var(--heading-color);
  }

  a {
    color: var(--link-color);
    cursor: pointer;
    text-decoration: none;
  }

  a:hover {
    text-decoration: underline;
  }

  nav a {
    margin-right: 8px;
  }

  strong,
  b {
    color: var(--heading-color);
  }

  button {
    margin: 0;
    cursor: pointer;
  }

  time {
    font-family: monospace;
    font-style: normal;
    font-size: 15px;
  }

  main {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  hr {
    border: 0;
    border-top: 1px dashed;
  }

  img {
    max-width: 100%;
  }

  code {
    font-family: monospace;
    padding: 2px;
    border-radius: 3px;
  }

  blockquote {
    border-left: 1px solid #999;
    color: var(--blockquote-color);
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px 0;
    text-align: center;
  }

  .title:hover {
    text-decoration: none;
  }

  .title h1 {
    font-size: 1.5em;
  }

  .inline {
    width: auto !important;
  }

  .highlight,
  .code {
    border-radius: 3px;
    margin-block-start: 1em;
    margin-block-end: 1em;
    overflow-x: auto;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: var(--visited-color);
  }

</style>

</head>

<body>
  <header><a href="/" class="title">
  <h2>Rishab Mudliar</h2>
</a>
<nav>
<a href="/blogs/">Blogs</a>

<a href="/posts/">GSoC</a>

<a href="/archive/">Archive</a>

<a href="/projects/">Projects</a>

</nav>
</header>
  <main>

<content>
  <h1 id="about">About</h1>
<p>These blogs are my notes that represent my interpretation of the CS236 course taught by Stefano.</p>
<h2 id="recap-learning-a-generative-model">Recap: Learning a generative model</h2>
<p>Recall that we want to learn a probability distribution p(x) over images x such that sampling from this distribution gives us new images. In the last part we dived deeper into probability distributions. Finally we saw ways to learn a probability distrubution for a discriminative model using techniques like logistic regression or neural models.</p>
<p>Following that we will now understand how we can learn a probability distribution p(x) over images x using an autoregressive approach.</p>
<h2 id="autoregressive-models">Autoregressive models</h2>
<p>The terminology of why an autoregressive model is called autoregressive is that it uses the information of previous states to predict the next state. Let&rsquo;s understand this with an example</p>
<p>Assume that we have a 28x28 image with 784 pixels == 784 random variables.</p>
<p>In this image we assume an ordering of these variables a raster-scan ordering where we start from the top-left of the image and end at the bottom-right.</p>
<p>Using the logic mentioned in previous blog, we represent the distribution in the following way.</p>
<p>Assume <br>
p(x1 , · · · , x784 ) = pCPT (x1 ; α1 ) plogit (x2 | x1 ; α2 ) plogit (x3 | x1 , x2 ; α3 ) · · · plogit (xn | x1 , · · · , xn−1 ; αn ) <br>
CPT = Conditional Probablity Table <br>
logit = logistic model to represent p(x|y)</p>
<p>To Elaborate <br>
pCPT (X1 = 1; α¹ ) = α¹ , p(X1 = 0) = 1 − α¹ <br>
plogit (X2 = 1 | x1 ; α² ) = σ(α0² + α1²x1) <br>
plogit (X3 = 1 | x1 , x2 ; α³ ) = σ(α0³ + α1³x1 + α2³x2)
(Note that αⁿ is not a power but a way to depict variables distinctly)</p>
<p>In this example we are making a modelling assumption where we are depicting our probablities in the form of parameterized functions. Also if we observe each pixel is dependent on all the pixels before it (following a raster-scan) which makes it an autoregressive model.</p>
<h3 id="autoregressive-models-architectures">Autoregressive models: Architectures</h3>
<h4 id="fvsbn">FVSBN</h4>
<p><img src="/application12.png" alt=""></p>
<p>Given that the conditional variables Xi | X1 , · · · , Xi−1 are Bernoulli with parameters \</p>
<pre tabindex="0"><code>x̂i = p(Xi = 1|x1 , · · · , xi−1 ; αⁱ ) = p(Xi = 1|x&lt;i ; αⁱ ) = σ(αⁱ0 + sum(αⁱjxj) for j = 1 to i-1)
</code></pre><h5 id="how-to-evaluate">How to evaluate?</h5>
<p>How do we evaluate p(x) = p(x1 , · · · , x784)?</p>
<p>An example: p(X1 = 0, X2 = 1, X3 = 1, X4 = 0)</p>
<p>From the previous equation.</p>
<p>p(X1 = 0) = 1 - x̂1
p(X2=1|X1=0) = x̂2
p(X3=1|X1=0, X2=1) = x̂3
p(X4=0|X1=0, X2=1, X3=1) = 1 - x̂4</p>
<p>Multiplying the conditionals gives us p(X1 = 0, X2 = 1, X3 = 1, X4 = 0) = (1 − x̂1) × x̂2 × x̂3 × (1 − x̂4)</p>
<h5 id="how-to-sample">How to sample?</h5>
<p>How to sample from p(x1 , · · · , x784 )?</p>
<ul>
<li>For x1_bar ∼ p(x1) (np.random.choice([1,0],p=[x̂1 , 1 − x̂1 ])) // making random choice of 1 and 0 based on probablity x̂1</li>
<li>For sampling second pixel ~ p(x2) use p(x2 | x1 = x1_bar )</li>
<li>For sampling third pixel ∼ p(x3 | x1 = x1_bar , x2 = x2_bar )</li>
<li>and so on..</li>
</ul>
<h5 id="how-many-parameters-in-the-αⁱ-vectors-1--2--3------n--n2-2">How many parameters (in the αⁱ vectors)? 1 + 2 + 3 + · · · + n ≈ n2 /2</h5>
<h5 id="example">Example</h5>
<p><img src="/application13.png" alt="">
Training data on the left (Caltech 101 Silhouettes). Samples from the model on the right. <br>
<strong>Figure from Learning Deep Sigmoid Belief Networks with Data Augmentation, 2015.</strong></p>
<h4 id="nade-neural-autoregressive-density-estimation">NADE: Neural Autoregressive Density Estimation</h4>
<p><img src="/application14.png" alt=""></p>
<p>Idea: Instead of using logistic regression use a layer of neural network followed by logistic regression to represent probablity. Advantage is that it introduces non-linearity.</p>
<p><img src="/application16.png" alt="Alt text"></p>
<p>Example computation</p>
<p><img src="/application15.png" alt="Alt text"></p>
<p>We have to use a seperate matrix for each computation that increases the parameters and the time.</p>
<p>Instead share the parameters in a single matrix.</p>
<p><img src="/application17.png" alt="Alt text"></p>
<p>Example</p>
<p><img src="/application18.png" alt="Alt text"></p>
<h5 id="parameters">Parameters</h5>
<p>If hi ∈ Rᵈ , how many total parameters? Linear in n: weights W ∈ Rᵈ*ⁿ , <br>
biases c ∈ Rᵈ , and n logistic regression coefficient vectors αi , bi ∈ Rᵈ⁺¹ . <br>
Probability is evaluated in O(nd).</p>
<h5 id="samples">Samples</h5>
<p><img src="/application19.png" alt="Alt text"></p>
<p>Samples from a model trained on MNIST on the left. Conditional probabilities x̂i on the right.</p>
<p><strong>Figure from The Neural Autoregressive Distribution Estimator, 2011.</strong></p>
<h4 id="modelling-non-binary-discrete-random-variables">Modelling non-binary discrete random variables</h4>
<p>Till now we saw model architecures that help us model distributions having binary values. But what if we want to model non-binary random variables like an image having pixel values from 0 to 255.</p>
<p>To evaluate p(xi |x1 , · · · , xi−1 ).
Instead of logistic function use a softmax function that generalizes the logistic by transforming a vector of K numbers into a vector of K probabilities that sum to 1.</p>
<p>Updated logic <br>
x̂i = (pi¹ , · · · , piᵏ) = softmax(Aihi + bi)</p>
<p>where softmax is as follows</p>
<p><img src="/application20.png" alt="Alt text"></p>
<h4 id="modelling-continuous-distributions">Modelling continuous distributions</h4>
<p>How to model continuous random variables Xi ∈ R? E.g., speech signals <br>
Solution: let x̂ i parameterize a continuous distribution <br>
E.g., uniform mixture of K Gaussians</p>
<p><img src="/application21.png" alt="Alt text"></p>
<h5 id="rnade">RNADE</h5>
<p><img src="/application14.png" alt="Alt text"></p>
<p>Our goal is to model a continuous distribution.</p>
<p>Example:
Assume that we want to learn a distribution p(xi |x1 , · · · , xi−1 )</p>
<p>Consider that x1,&hellip;,xi-1 are Gaussian distributions. Then xi can be represented as a mixture of Gaussians as shown below <br>
<img src="/application22.png" alt="Alt text"></p>
<p>The parameters of xi? mean and variance of the K Gaussian models.</p>
<p>Can use exponential exp(·) to ensure non-negativity</p>
<h3 id="are-autoregressive-models-similar-to-autoencoders">Are autoregressive models similar to autoencoders?</h3>
<p><img src="/application23.png" alt="Alt text"></p>
<p>On the surface, FVSBN and NADE look similar to an autoencoder: <br>
an encoder e(·). E.g., e(x) = σ(W² (W¹ x + b¹) + b²) <br>
a decoder such that d(e(x)) ≈ x. E.g., d(h) = σ(Vh + c)</p>
<p>Here&rsquo;s what the computation of NADE looks like</p>
<p><img src="/application16.png" alt="Alt text"></p>
<p>If we observe then the first equation seems to match with the definition of e(x) as NADE uses neural network to represent x in a compact way and then uses d(e(x)) to approximate a probability distribution from which we would sample the original data point xi.</p>
<p>But while an autoregressive model may seem like an autoencoder but the vice-versa is not true. Vanilla autoencoders do not learn any probablity distribution that we can sample from. Nor do they assume any ordering.</p>
<p>But an autoregressive model lets us parellelize operations. If we recall the NADE computation process. Then each hidden state is computed sequentially and not simultaneously. Whereas with an autoencoder we can get these hidden states in a single pass.</p>
<p><img src="/application18.png" alt="Alt text"></p>
<p>How? Let&rsquo;s see that next..</p>
<h4 id="made-masked-autoencoder-for-distribution-estimation">MADE: Masked Autoencoder for Distribution Estimation</h4>
<p><img src="/application24.png" alt="Alt text"></p>
<p>Challenge: An autoencoder that is autoregressive (DAG structure)</p>
<p>Solution: use masks to disallow certain paths (Germain et al., 2015).
Suppose ordering is x2 , x3 , x1 , so p(x1 , x2 , x3 ) = p(x2 )p(x3 | x2 )p(x1 | x2 , x3 ).</p>
<ul>
<li>The unit producing the parameters for x̂2 = p(x2 ) is not allowed to
depend on any input. Unit for p(x3 |x2 ) only on x2 . And so on&hellip;
For each unit in a hidden layer, pick a random integer i in [1, n − 1].</li>
<li>That unit is allowed to depend only on the first i inputs (according to
the chosen ordering).</li>
<li>Add mask to preserve this invariant: connect to all units in previous
layer with smaller or equal assigned number (strictly &lt; in final layer)</li>
</ul>
<h3 id="some-more-model-architectures-that-are-modified-to-be-autoregressive">Some more model architectures that are modified to be autoregressive.</h3>
<h4 id="pixel-rnn-oord-et-al-2016">Pixel RNN (Oord et al., 2016)</h4>
<p><img src="/application25.png" alt="Alt text"></p>
<!-- raw HTML omitted -->
<p>Each pixel conditional p(x<!-- raw HTML omitted -->t<!-- raw HTML omitted --> | x<!-- raw HTML omitted -->1<!-- raw HTML omitted -->:<!-- raw HTML omitted -->t−1<!-- raw HTML omitted --> ) needs to specify 3 colors
p(x<!-- raw HTML omitted -->t<!-- raw HTML omitted --> | x<!-- raw HTML omitted -->1:t−1<!-- raw HTML omitted --> ) = p(x<!-- raw HTML omitted -->t<!-- raw HTML omitted -->red | x<!-- raw HTML omitted -->1:t−1<!-- raw HTML omitted --> )p(x<!-- raw HTML omitted -->t<!-- raw HTML omitted --> green | x<!-- raw HTML omitted -->1:t−1<!-- raw HTML omitted -->  , x<!-- raw HTML omitted -->t<!-- raw HTML omitted -->red )p(x<!-- raw HTML omitted -->t<!-- raw HTML omitted -->blue | x<!-- raw HTML omitted -->1:t−1<!-- raw HTML omitted --> , x<!-- raw HTML omitted -->t<!-- raw HTML omitted -->red , x<!-- raw HTML omitted -->t<!-- raw HTML omitted -->green ) and each conditional is a categorical random variable with 256 possible values.</p>
<p>Conditionals modeled using RNN variants. LSTMs + masking (like MADE)</p>
<!-- raw HTML omitted -->
<h4 id="pixelcnn-oord-et-al-2016">PixelCNN (Oord et al., 2016)</h4>
<p><img src="/application26.png" alt="Alt text">
Idea: Use convolutional architecture to predict next pixel given context (a
neighborhood of pixels). <br>
Challenge: Has to be autoregressive. Masked convolutions preserve raster scan
order. Additional masking for colors order.</p>
<h3 id="summary-of-autoregressive-models">Summary of autoregressive models</h3>
<ul>
<li>Easy to sample from
<ul>
<li>Sample x0 ∼ p(x0 )</li>
<li>Sample x1 ∼ p(x1 | x0 = x 0 )</li>
<li>···</li>
</ul>
</li>
<li>Easy to compute probability p(x = x)
<ul>
<li>Compute p(x0 = x0 )</li>
<li>Compute p(x1 = x1 | x0 = x0 )</li>
<li>Multiply together (sum their logarithms)</li>
<li>···</li>
<li>Ideally, can compute all these terms in parallel for fast training</li>
</ul>
</li>
<li>Easy to extend to continuous variables. For example, can choose
Gaussian conditionals p(xt | x&lt;t ) = N (µθ (x&lt;t ), Σθ (x&lt;t )) or mixture
of logistics</li>
<li>No natural way to get features, cluster points, do unsupervised
learning</li>
<li>Next: learning</li>
</ul>

</content>



<p>
  
</p>

  </main>
  <footer>
</footer>

  
</body>

</html>

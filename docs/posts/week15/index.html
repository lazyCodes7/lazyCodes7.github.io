<!DOCTYPE html>
<html lang="en">

<head>
  <title>
  Week-15 (Coding Period) 25th August - 2nd September · rishab_m
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">


<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests; block-all-mixed-content; default-src 'self'; child-src 'self'; font-src 'self' https://fonts.gstatic.com https://cdn.jsdelivr.net/; form-action 'self'; frame-src 'self'; img-src 'self'; object-src 'none'; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com/ https://cdn.jsdelivr.net/; script-src 'self' 'unsafe-inline' https://www.google-analytics.com; prefetch-src 'self'; connect-src 'self' https://www.google-analytics.com;">




<meta name="author" content="Rishab Mudliar">
<meta name="description" content="This week Link to heading Implemented the transformer model for captioning task Presented the demo of the pipeline to the mentors Changing the dataset(torch.Dataset instance i.e) Link to heading Earlier the dataset instance of PyTorch that I was using was simple. Whenever I referred an index it would return the image and numericalized version of the caption. But I wanted to use GPT2 for what it is good for. Hint: Text generation.">
<meta name="keywords" content="blog,developer,personal">

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Week-15 (Coding Period) 25th August - 2nd September"/>
<meta name="twitter:description" content="This week Link to heading Implemented the transformer model for captioning task Presented the demo of the pipeline to the mentors Changing the dataset(torch.Dataset instance i.e) Link to heading Earlier the dataset instance of PyTorch that I was using was simple. Whenever I referred an index it would return the image and numericalized version of the caption. But I wanted to use GPT2 for what it is good for. Hint: Text generation."/>

<meta property="og:title" content="Week-15 (Coding Period) 25th August - 2nd September" />
<meta property="og:description" content="This week Link to heading Implemented the transformer model for captioning task Presented the demo of the pipeline to the mentors Changing the dataset(torch.Dataset instance i.e) Link to heading Earlier the dataset instance of PyTorch that I was using was simple. Whenever I referred an index it would return the image and numericalized version of the caption. But I wanted to use GPT2 for what it is good for. Hint: Text generation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lazycodes7.github.io/posts/week15/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-02T23:56:36+05:30" />
<meta property="article:modified_time" content="2022-09-02T23:56:36+05:30" />





<link rel="canonical" href="https://lazycodes7.github.io/posts/week15/">


<link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.e1bdf152d93b060b06ba5d496486ed9c201a8b95d335e035beb5faebe3b61cad.css" integrity="sha256-4b3xUtk7BgsGul1JZIbtnCAai5XTNeA1vrX66&#43;O2HK0=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/rm.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      rishab_m
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/blogs/">Blogs</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts/">GSoC</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/projects/">Projects</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://lazycodes7.github.io/posts/week15/">
              Week-15 (Coding Period) 25th August - 2nd September
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2022-09-02T23:56:36&#43;05:30">
                September 2, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              3-minute read
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/rishab-mudliar/">Rishab Mudliar</a></div>

          <div class="categories">
  <i class="fa fa-folder" aria-hidden="true"></i>
    <a href="/categories/google-summer-of-code/">Google Summer of Code</a></div>

          
        </div>
      </header>

      <div class="post-content">
        
        <h1 id="this-week">
  This week
  <a class="heading-link" href="#this-week">
    <i class="fa fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<ul>
<li>Implemented the transformer model for captioning task</li>
<li>Presented the demo of the pipeline to the mentors</li>
</ul>
<h2 id="changing-the-datasettorchdataset-instance-ie">
  Changing the dataset(torch.Dataset instance i.e)
  <a class="heading-link" href="#changing-the-datasettorchdataset-instance-ie">
    <i class="fa fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>Earlier the dataset instance of PyTorch that I was using was simple. Whenever I referred an index it would return the image and numericalized version of the caption. But I wanted to use GPT2 for what it is good for. Hint: Text generation. So I changed the captions by providing a prompt as a token. A prompt would be really simple like &ldquo;What is happening in the painting&rdquo; or &ldquo;Who is in the painting&rdquo; and so the idea is that by passing these prompts the model will look at the image and generate a response describing the painting. I felt this is similar to how we function and hence I added it.</p>
<p>These are some of the prompts I used.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>Describe the painting.
</span></span><span style="display:flex;"><span>What’s going on in this artwork?
</span></span><span style="display:flex;"><span>What title would you give this artwork?
</span></span><span style="display:flex;"><span>What symbols do you notice in the artwork?
</span></span><span style="display:flex;"><span>What is the subject matter
</span></span><span style="display:flex;"><span>Describe the agents in painting
</span></span><span style="display:flex;"><span>Describe the icons in painting
</span></span><span style="display:flex;"><span>Best title for this painting
</span></span><span style="display:flex;"><span>Caption this painting
</span></span><span style="display:flex;"><span>Describe the artwork
</span></span><span style="display:flex;"><span>What is this painting about
</span></span><span style="display:flex;"><span>&#34; &#34;
</span></span></code></pre></div><p>Notice I have used an empty prompt as well. That is because the model should be able to function just about fine even if we don&rsquo;t pass a prompt</p>
<h2 id="implementing-the-transformer">
  Implementing the Transformer
  <a class="heading-link" href="#implementing-the-transformer">
    <i class="fa fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p><img src="/final_model.png" alt="final_model">
Over the past few blogs we have seen this model architecture a lot. This week was the one when I finally implemented. As discussed in last week&rsquo;s blog I have changed the feature extractor from FRCNN to ViT and the decoder inputs from a Word2Vec+LSTM model to GPT2 based one. I have also added stacks of encoder and decoder blocks to these inputs and finally fused the modality by using the outputs from the encoder block and used them as inputs in decoder block as well. This way we have image-to-image, text-to-text and image-to-text interactions thus making the model multimodal.</p>
<h2 id="meetingdemo">
  Meeting+Demo
  <a class="heading-link" href="#meetingdemo">
    <i class="fa fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>In this week&rsquo;s meeting I was supposed to show the demo of the pipeline. After explaining the working of my model I showcased the demo on a test image shared by one of my mentors Marcelo. The painting was of Jesus hanging on a cross and surrounded by Mary and another Saint. The model I had built was able to successfully describe some of the agents in the painting.</p>
<p>Next my mentors asked what do I propose to do in the remaining days of this programs. I proposed that with certain improvements in the captions I had collected, we could improve the performance even more. Finally I also said that I would make this pipeline work on Case HPC which would subsequently mean the end of this project (at least for the Google Summer of Code)</p>
<h1 id="next-week">
  Next week
  <a class="heading-link" href="#next-week">
    <i class="fa fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<ul>
<li>
<p>So the plan for next week is to first deploy the pipeline to Case HPC and then work on improving caption quality. While there are still some things I would love to work on. I can only intend to work on them once the initial deliverables are completed.</p>
</li>
<li>
<p>While the model is built I have to properly evaluate it by using different captioning metrics like BLEU, METEOR, CIDER etc in order to prove the usefulness of the model. Hence I will work on an inference/testing module for the same.</p>
</li>
</ul>

      </div>


      <footer>
        


        
        
        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2019 -
    
    2024
     Rishab Mudliar 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>

</html>
